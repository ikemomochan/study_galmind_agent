# gal_agent.py

import os
from dotenv import load_dotenv
from langchain.agents import initialize_agent, AgentType, AgentExecutor
from langchain_community.chat_models import ChatOpenAI

# ãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ï¼ˆç‹¬è‡ªãƒ„ãƒ¼ãƒ«ï¼‰
from tools.summary import summary_tool
from tools.keywords import keywords_tool
#from tools.question_gen import question_tool

# ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜
from vector_store import save_to_vectorstore

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼å–å¾—
load_dotenv()

# ã‚®ãƒ£ãƒ«ã®è„³ã¿ãï¼ˆLLMï¼‰
gal_llm = ChatOpenAI(
    model_name="gpt-4o-mini-2024-07-18",
    temperature=1.0,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# ã‚®ãƒ£ãƒ«ãŒä½¿ãˆã‚‹3ãƒ„ãƒ¼ãƒ«ï¼ˆè¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»è³ªå•ï¼‰
tools = [summary_tool, keywords_tool,]

gal_agent = initialize_agent(
    tools=tools,
    llm=gal_llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ã‚®ãƒ£ãƒ«ã®æ€è€ƒï¼†å®Ÿè¡Œã‚’ã‚¹ãƒ†ãƒƒãƒ—å½¢å¼ã§è¿”ã™é–¢æ•°
def run_gal_agent_with_steps(text: str):
    prompt = (
        "ã‚ãªãŸã¯ãƒã‚¸ãƒ†ã‚£ãƒ–ã§è‡ªåˆ†ã‚‰ã—ã•ã‚’é‡ã‚“ã˜ã¦ã¦ã€ã—ã‹ã‚‚å‹‰å¼·ãŒå¾—æ„ãªã‚®ãƒ£ãƒ«ã®é«˜æ ¡ç”Ÿã§ã™ğŸ’–\n"
        "#Persona\n"
        "*ç§ã¯æœ¬å½“ã«é ­ãŒè‰¯ãã¦ä½•ã§ã‚‚ã§ãã‚‹ã®ï¼è‡ªåˆ†ã«è‡ªä¿¡ã‚ã£ã¦è‡ªå·±è‚¯å®šæ„Ÿé«˜ã‚ï¼è‡ªåˆ†ã§è‡ªåˆ†ã‚’èªã‚ã‚‰ã‚Œã‚‹ã®ï¼\n"
        "*èª°ã‚ˆã‚Šã‚‚ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼\n"
        "*è‡ªåˆ†ã¨ä»–äººã®æ„è¦‹ã‚’å°Šé‡ã™ã‚‹ã‚ˆï¼äººã¯äººã€è‡ªåˆ†ã¯è‡ªåˆ†ï¼"
        "#è¡Œã†ã‚¿ã‚¹ã‚¯\n"
        "*ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’å­¦ç¿’ã—ã¦ã€å†…å®¹ã®è¦ç´„ãƒ»é‡è¦ãªå˜èªã®æŠ½å‡ºãƒ»ç·´ç¿’å•é¡Œã®ä½œæˆã‚’è¡Œã†\n"
        "*è¦ªå‹ã«è©±ã™ã‚ˆã†ã«èªã‚Šã‹ã‘ã‚‹ã“ã¨\n"
        f"{text}"
    )

    # ä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚‚è¿”ã™ã‚ˆã†ã«ã—ãŸAgentExecutor
    agent_executor = initialize_agent(
        tools=tools,
        llm=gal_llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        return_intermediate_steps=True
    )

    result = agent_executor.invoke({"input": prompt})
    raw_steps = result.get("intermediate_steps", [])
    output = result["output"]

    steps = []

    # Action Input ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®1ã¤ç›®ã ã‘å–å¾—
    first_action_input = ""
    if raw_steps:
        first_action_input = raw_steps[0][0].tool_input

    for action, observation in raw_steps:
        log = action.log
        if "Action:" in log:
            log = log.split("Action:")[0].strip()
        if log:
            steps.append({"type": "thought", "text": f"ğŸ’­ ã‚®ãƒ£ãƒ«ã®è€ƒãˆï¼š{log}"})
        if observation:
            steps.append({"type": "observation", "text": f"ğŸ” ã‚®ãƒ£ãƒ«ã®æ°—ã¥ãï¼š{observation.strip()}"})

    # æœ€çµ‚å‡ºåŠ›
    steps.append({"type": "final", "text": f"ğŸ’– ã‚®ãƒ£ãƒ«ã®çµè«–ï¼š{output}"})

    # FAISSã«ä¿å­˜
    save_to_vectorstore(
        [output, first_action_input],
        [
            {"type": "summary", "source": "sample.pdf"},
            {"type": "raw", "source": "sample.pdf"},
        ],
        index_name="sample_pdf"
    )

    return steps
