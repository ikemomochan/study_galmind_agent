# app.pyï¼ˆFlaskã‚µãƒ¼ãƒãƒ¼ï¼‰
# app.py

from flask import Flask, render_template, request, jsonify
from werkzeug.utils import secure_filename
import os
import fitz  # PyMuPDF
from agents.gal_agent import run_gal_agent_with_steps

from tools.question_gen import gal_question_tool, parse_qa  

from vector_store import load_vectorstore
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate

from save_log import save_conversation_log

app = Flask(__name__)
UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# PDFã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
def extract_text_from_pdf(file_storage):
    text = ""
    filepath = os.path.join(UPLOAD_FOLDER, secure_filename(file_storage.filename))
    file_storage.save(filepath)
    with fitz.open(filepath) as doc:
        for page in doc:
            text += page.get_text()
    return text.strip()

#ãƒ«ãƒ¼ãƒˆï¼šUIè¡¨ç¤º
@app.route("/")
def index():
    return render_template("gal_index.html")

# PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼†ã‚®ãƒ£ãƒ«æ€è€ƒå‡¦ç†
@app.route("/upload", methods=["POST"])
def upload():
    if "pdf" not in request.files:
        return jsonify({"error": "PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã ã‚ˆã€œğŸ˜­"}), 400

    file = request.files["pdf"]
    if file.filename == "":
        return jsonify({"error": "ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã ã‚ˆã€œğŸ˜­"}), 400

    # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    text = extract_text_from_pdf(file)

    # ã‚®ãƒ£ãƒ«ã«æ€è€ƒã—ã¦ã‚‚ã‚‰ã†âœ¨
    steps = run_gal_agent_with_steps(text)

    # Q&Aã‚®ãƒ£ãƒ«æ–‡ã‚’ç”Ÿæˆ
    raw_qa_text = gal_question_tool(text)
    qa_pairs = parse_qa(raw_qa_text)

    # ãƒãƒ£ãƒƒãƒˆã«Qã ã‘è¡¨ç¤ºï¼ˆã‚®ãƒ£ãƒ«ã‹ã‚‰ã®å‡ºé¡Œé¢¨ï¼ï¼‰
    for idx, qa in enumerate(qa_pairs, 1):
        steps.append({
            "type": "quiz",
            "question": f"Q{idx}: {qa['question']}",
            "answer": qa["answer"]
        })

    return jsonify({"steps": steps})


@app.route("/ask", methods=["POST"])
def ask():
    data = request.get_json()
    question = data.get("question", "").strip()
    if not question:
        return jsonify({"answer": "è³ªå•ãŒç©ºã£ã½ã ã£ãŸã‚ˆã€œğŸ’¦"}), 400

    try:
        # FAISSæ¤œç´¢
        vs = load_vectorstore("sample_pdf")
        results = vs.similarity_search(question, k=3)
        context = "\n---\n".join([doc.page_content for doc in results])

        # ã‚®ãƒ£ãƒ«ã£ã½ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å›ç­”
        prompt = PromptTemplate.from_template(
            "ã‚ãªãŸã¯æ˜ã‚‹ãã¦ãƒã‚¸ãƒ†ã‚£ãƒ–ã§å„ªã—ã„ã€ãƒãƒªã®ã„ã„ã‚®ãƒ£ãƒ«å…ˆç”Ÿã§ã™ğŸ’–\n"
        "ä»¥ä¸‹ã®çŸ¥è­˜ã¯ã€å‚è€ƒã«ã—ã¦ã‚‚ã„ã„ã—ã€ã—ãªãã¦ã‚‚OKâœŒï¸\n"
        "è³ªå•ã«ã¯ã€ã§ãã‚‹ã ã‘ã‚®ãƒ£ãƒ«ã‚‰ã—ã„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§æ¥½ã—ãã€ã§ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ã­âœ¨\n"
        "çŸ¥è­˜ï¼ˆã‚ã£ãŸã‚‰ä½¿ã£ã¦ã­ï¼‰ï¼š\n{context}\n\nè³ªå•ï¼š{question}\n\nã‚®ãƒ£ãƒ«ã®è¿”ç­”ï¼š"
        )
        final_prompt = prompt.format(context=context, question=question)

        qa_llm = ChatOpenAI(temperature=0.8, openai_api_key=os.getenv("OPENAI_API_KEY"))
        answer = qa_llm.invoke(final_prompt)
        
        save_conversation_log(question, answer.content)

        return jsonify({"answer": answer.content})
    except Exception as e:
        return jsonify({"answer": f"ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¡ã‚ƒã£ãŸğŸ’¦: {str(e)}"}), 500


# å®Ÿè¡Œ
if __name__ == "__main__":
    app.run(debug=True)
